

## Hash-like Filters & Fast Hashing for Hash Tables et al (64 bits and less, mostly)

These hashes are for other purposes, e.g. fast lookup in dictionaries, fast approximate hit testing and set reduction through fast filtering (think *bloom filter*). These *may* be **machine specific** (and some of them *are*): these are **never supposed to be used for encoding in storage or other means which crosses machine boundaries**: if you want to use them for a database index, that is fine *as long as* you don't expect that database index to be readable by any other machine than the one which produced and uses these hash numbers.

> As you can see from the list below, I went on a shopping spree, having fun with all the latest, including some *possibly insane* stuff that's only really useful for particular edge cases -- which we *hope to avoid ourselves, for a while at least*. Anyway, I'ld say we've got the motherlode here. Simple fun for those days when your brain-flag is at half-mast. Enjoy.

- **adaptiveqf** [ğŸ“](./adaptiveqf) [ğŸŒ](https://github.com/GerHobbelt/adaptiveqf) -- [Adaptive Quotient Filter (AQF)](https://arxiv.org/abs/2107.02866) supports approximate membership testing and counting the occurrences of items in a data set. Like other AMQs, the AQF has a chance for false positives during queries. However, the AQF has the ability to adapt to false positives after they have occurred so they are not repeated. At the same time, the AQF maintains the benefits of a quotient filter, as it is small and fast, has good locality of reference, scales out of RAM to SSD, and supports deletions, counting, resizing, merging, and highly concurrent access.
- **adaptive-radix-tree** [ğŸ“](./adaptive-radix-tree) [ğŸŒ](https://github.com/GerHobbelt/adaptive-radix-tree) -- implements the Adaptive Radix Tree (ART), as proposed by Leis et al. ART, which is a trie based data structure, achieves its performance, and space efficiency, by compressing the tree both vertically, i.e., if a node has no siblings it is merged with its parent, and horizontally, i.e., uses an array which grows as the number of children increases. Vertical compression reduces the tree height and horizontal compression decreases a nodeâ€™s size.
- **BBHash** [ğŸ“](./BBHash) [ğŸŒ](https://github.com/GerHobbelt/BBHash) -- Bloom-filter based minimal perfect hash function library.
  
  - **left-for-dead**; reason: has some GCC + Linux specific coding constructs; code isn't clean, which doesn't make my porting effort 'trustworthy'. Overall, if this is the alternative, we'll stick with `gperf`.

- **BCF-cuckoo-index** [ğŸ“](./BCF-cuckoo-index) [ğŸŒ](https://github.com/GerHobbelt/BCF) -- Better Choice Cuckoo Filter (BCF) is an efficient approximate set representation data structure. Different from the standard Cuckoo Filter (CF), BCF leverages the principle of the power of two choices to select the better candidate bucket during insertion. BCF reduces the average number of relocations of the state-of-the-art CF by 35%.
  
  - **left-for-dead**; reason: has some GCC + Linux specific coding constructs: intrinsics + Linux-only API calls, which increase the cost of porting.

- **bitrush-index** [ğŸ“](./bitrush-index) [ğŸŒ](https://github.com/GerHobbelt/bitrush-index) -- provides a serializable bitmap index able to index millions values/sec on a single thread. By default this library uses [ozbcbitmap] but if you want you can also use another compressed/uncrompressed bitmap. Only equality-queries (A = X) are supported.
- **bloom** [ğŸ“](./bloom) [ğŸŒ](https://github.com/GerHobbelt/bloom) -- C++ Bloom Filter Library, which offers optimal parameter selection based on expected false positive rate, union, intersection and difference operations between bloom filters and compression of in-use table (increase of false positive probability vs space).
- **blurhash** [ğŸ“](./blurhash) [ğŸŒ](https://github.com/GerHobbelt/blurhash) -- generates a compact representation of a placeholder for an image. You can also see nice examples and try it out yourself at [blurha.sh](http://blurha.sh/)! BlurHash takes an image and gives you a short string (only 20-30 characters!) that represents the placeholder for this image, which can be quickly decoded by any web client into an image that it shows while the real image is loading over the network.
- **cmph-hasher** [ğŸ“](./cmph-hasher) [ğŸŒ](https://github.com/GerHobbelt/cmph) -- C Minimal Perfect Hashing Library for both small and (very) large hash sets.
- **cqf** [ğŸ“](./cqf) [ğŸŒ](https://github.com/GerHobbelt/cqf) -- [A General-Purpose Counting Filter: Counting Quotient Filter (CQF)](https://dl.acm.org/doi/10.1145/3035918.3035963) supports approximate membership testing and counting the occurrences of items in a data set. This general-purpose AMQ is small and fast, has good locality of reference, scales out of RAM to SSD, and supports deletions, counting (even on skewed data sets), resizing, merging, and highly concurrent access.
- **crc32** [ğŸ“](./crc32) [ğŸŒ](https://github.com/GerHobbelt/crc32) -- fast CRC32 library from https://create.stephan-brumme.com/crc32/
- **crc32c** [ğŸ“](./crc32c) [ğŸŒ](https://github.com/GerHobbelt/crc32c) -- a few CRC32C implementations under an umbrella that dispatches to a suitable implementation based on the host computer's hardware capabilities. CRC32C is specified as the CRC that uses the iSCSI polynomial in [RFC 3720](https://tools.ietf.org/html/rfc3720#section-12.1). The polynomial was introduced by G. Castagnoli, S. Braeuer and M. Herrmann. CRC32C is used in software such as Btrfs, ext4, Ceph and leveldb.
- **CRoaring** [ğŸ“](./CRoaring) [ğŸŒ](https://github.com/GerHobbelt/CRoaring) -- portable Roaring bitmaps in C (and C++). Bitsets, also called bitmaps, are commonly used as fast data structures. Unfortunately, they can use too much memory. To compensate, we often use compressed bitmaps. Roaring bitmaps are compressed bitmaps which tend to outperform conventional compressed bitmaps such as WAH, EWAH or Concise. They are used by several major systems such as Apache Lucene and derivative systems such as Solr and Elasticsearch, etc.. The CRoaring library is used in several systems such as Apache Doris.
- **cuckoofilter** [ğŸ“](./cuckoofilter) [ğŸŒ](https://github.com/GerHobbelt/cuckoofilter) -- a key-value filter using cuckoo hashing, a Bloom filter replacement for approximated set-membership queries. While Bloom filters are well-known space-efficient data structures to serve queries like "if item x is in a set?", they do not support deletion. Their variances to enable deletion (like counting Bloom filters) usually require much more space.  Cuckoo ï¬lters provide the ï¬‚exibility to add and remove items dynamically. A cuckoo filter is based on cuckoo hashing (and therefore named as cuckoo filter).  It is essentially a cuckoo hash table storing each key's fingerprint. Cuckoo hash tables can be highly compact, thus a cuckoo filter could use less space than conventional Bloom ï¬lters, for applications that require low false positive rates (< 3%).
- **Cuckoo_Filter_simple** [ğŸ“](./Cuckoo_Filter_simple) [ğŸŒ](https://github.com/GerHobbelt/Cuckoo_Filter) -- a key-value filter using cuckoo hashing, substituting for bloom filter.
- **cuckoo-index** [ğŸ“](./cuckoo-index) [ğŸŒ](https://github.com/GerHobbelt/cuckoo-index) -- Cuckoo Index (CI) is a lightweight secondary index structure that represents the many-to-many relationship between keys and partitions of columns in a highly space-efficient way. CI associates variable-sized fingerprints in a Cuckoo filter with compressed bitmaps indicating qualifying partitions. The problem of finding all partitions that possibly contain a given lookup key is traditionally solved by maintaining one filter (e.g., a Bloom filter) per partition that indexes all unique key values contained in this partition. To identify all partitions containing a key, we would need to probe all per-partition filters (which could be many). Depending on the storage medium, a false positive there can be very expensive. Furthermore, secondary columns typically contain many duplicates (also across partitions). Cuckoo Index (CI) addresses these drawbacks of per-partition filters. (It must know all keys at build time, though.)
- **dablooms** [ğŸ“](./dablooms) [ğŸŒ](https://github.com/GerHobbelt/dablooms) -- a Scalable, Counting, Bloom Filter demonstrating a novel Bloom filter implementation that can scale, and provide not only the addition of new members, but reliable removal of existing members.
- **DCF-cuckoo-index** [ğŸ“](./DCF-cuckoo-index) [ğŸŒ](https://github.com/GerHobbelt/DCF) -- the Dynamic Cuckoo Filter (DCF) is an efficient approximate membership test data structure. Different from the classic Bloom filter and its variants, DCF is especially designed for highly dynamic datasets and supports extending and reducing its capacity. The DCF design is the first to achieve both reliable item deletion and flexibly extending/reducing for approximate set representation and membership testing. DCF outperforms the state-of-the-art DBF designs in both speed and memory consumption.
- **dense_hash_map** [ğŸ“](./dense_hash_map) [ğŸŒ](https://github.com/GerHobbelt/dense_hash_map) -- `jg::dense_hash_map`: a simple replacement for `std::unordered_map` with better performance but loose stable addressing as a trade-off.
- **EASTL** [ğŸ“](./EASTL) [ğŸŒ](https://github.com/GerHobbelt/EASTL) -- EASTL (Electronic Arts Standard Template Library) is a C++ template library of containers, algorithms, and iterators useful for runtime and tool development across multiple platforms. It is a fairly extensive and robust implementation of such a library and has an emphasis on high performance above all other considerations.
- **emhash** [ğŸ“](./emhash) [ğŸŒ](https://github.com/GerHobbelt/emhash) -- fast and memory efficient open addressing C++ flat hash table/map.
- **emphf-hash** [ğŸ“](./emphf-hash) [ğŸŒ](https://github.com/GerHobbelt/emphf) -- an efficient external-memory algorithm for the construction of minimal perfect hash functions for large-scale key sets, focusing on speed and low memory usage (2.61 N bits plus a small constant factor).
- **EWAHBoolArray** [ğŸ“](./EWAHBoolArray) [ğŸŒ](https://github.com/GerHobbelt/EWAHBoolArray) -- a C++ compressed bitset data structure (also called bitset or bit vector). It supports several word sizes by a template parameter (16-bit, 32-bit, 64-bit). You should expect the 64-bit word-size to provide better performance, but higher memory usage, while a 32-bit word-size might compress a bit better, at the expense of some performance.
- **eytzinger** [ğŸ“](./eytzinger) [ğŸŒ](https://github.com/GerHobbelt/eytzinger) -- `fixed_eytzinger_map` is a free implementation of Eytzingerâ€™s layout, in a form of an STL-like generic associative container, broadly compatible with a well-established access patterns. An Eytzinger map, or BFS(breadth-first search) map, places elements in a lookup order, which leads to a better memory locality. In practice, such container can outperform searching in sorted arrays, like `boost::flat_map`, due to less cache misses made in a lookup process. In comparison with RB-based trees, like `std::map`, lookup in Eytzinger map can be multiple times faster. Some comparison graphs are [given here](https://kazakov.life/2017/03/06/cache-friendly-associative-container/).
- **farmhash** [ğŸ“](./farmhash) [ğŸŒ](https://github.com/GerHobbelt/farmhash) -- FarmHash, a family of hash functions. FarmHash provides hash functions for strings and other data.  The functions mix the input bits thoroughly but are not suitable for cryptography.
- **fastfilter_cpp** [ğŸ“](./fastfilter_cpp) [ğŸŒ](https://github.com/GerHobbelt/fastfilter_cpp) -- Fast Filter: Fast approximate membership filter implementations (C++, research library)
- **fasthashing** [ğŸ“](./fasthashing) [ğŸŒ](https://github.com/GerHobbelt/fasthashing) -- a few very fast (almost) strongly universal hash functions over 32-bit strings, as described by the paper:  Owen Kaser and Daniel Lemire, Strongly universal string hashing is fast, Computer Journal (2014) 57 (11): 1624-1638. http://arxiv.org/abs/1202.4961
- **fifo_map** [ğŸ“](./fifo_map) [ğŸŒ](https://github.com/GerHobbelt/fifo_map) -- a FIFO-ordered associative container for C++. It has the same interface as `std::map`, it can be used as drop-in replacement.
- **flat_hash_map** [ğŸ“](./flat_hash_map) [ğŸŒ](https://github.com/GerHobbelt/flat_hash_map) -- a very fast hashtable.
- **flat.hpp** [ğŸ“](./flat.hpp) [ğŸŒ](https://github.com/GerHobbelt/flat.hpp) -- a library of flat vector-like based associative containers.
- **fph-table** [ğŸ“](./fph-table) [ğŸŒ](https://github.com/GerHobbelt/fph-table) -- the Flash Perfect Hash (FPH) library is a modern C++/17 implementation of a dynamic [perfect hash](https://en.wikipedia.org/wiki/Perfect_hash_function) table (no collisions for the hash), which makes the hash map/set extremely fast for lookup operations. We provide four container classes `fph::DynamicFphSet`,`fph::DynamicFphMap`,`fph::MetaFphSet` and `fph::MetaFphMap`. The APIs of these four classes are almost the same as those of `std::unordered_set` and `std::unordered_map`.
- **fsst** [ğŸ“](./fsst) [ğŸŒ](https://github.com/GerHobbelt/fsst) -- Fast Static Symbol Table (FSST): fast text compression that allows random access. See also the PVLDB paper https://github.com/cwida/fsst/raw/master/fsstcompression.pdf. FSST is a compression scheme focused on string/text data: it can compress strings from distributions with many different values (i.e. where dictionary compression will not work well). It allows *random-access* to compressed data: it is not block-based, so individual strings can be decompressed without touching the surrounding data in a compressed block. When compared to e.g. LZ4 (which is block-based), FSST further achieves similar decompression speed and compression speed, and better compression ratio. FSST encodes strings using a symbol table -- but it works on pieces of the string, as it maps "symbols" (1-8 byte sequences) onto "codes" (single-bytes). FSST can also represent a byte as an exception (255 followed by the original byte). Hence, compression transforms a sequence of bytes into a (supposedly shorter) sequence of codes or escaped bytes. These shorter byte-sequences could be seen as strings again and fit in whatever your program is that manipulates strings. An optional 0-terminated mode (like, C-strings) is also supported.
- **gperf-hash** [ğŸ“](./gperf-hash) [ğŸŒ](https://github.com/GerHobbelt/gperf) -- This is GNU gperf, a program that generates C/C++ perfect hash functions for sets of key words.
- **gtl** [ğŸ“](./gtl) [ğŸŒ](https://github.com/GerHobbelt/gtl) -- Greg's Template Library of useful classes, including a set of excellent **hash map** implementations, as well as a **btree** alternative to `std::map` and `std::set`. These are *drop-in replacements* for the standard C++ classes and provide the same API, but are significantly faster and use less memory. We also have a fast `bit_vector` implementation, which is an alternative to `std::vector<bool>` or `std::bitset`, providing both dynamic resizing and a good assortment of bit manipulation primitives, as well as a novel `bit_view` class allowing to operate on subsets of the `bit_vector`. We have `lru_cache` and `memoize` classes, both with very fast multi-thread versions relying of the mutex sharding of the parallel hashmap classes. We also offer an `intrusive_ptr` class, which uses less memory than `std::shared_ptr`, and is simpler to construct.
- **HashMap** [ğŸ“](./HashMap) [ğŸŒ](https://github.com/GerHobbelt/HashMap) -- a hash table mostly compatible with the C++11 *std::unordered_map* interface, but with much higher performance for many workloads. This hash table uses open addressing with linear probing and backshift deletion. Open addressing and linear probing minimizes memory allocations and achieves high cache efficiency. Backshift deletion keeps performance high for delete heavy workloads by not clobbering the hash table with tombestones.
- **hashtable-bench** [ğŸ“](./hashtable-bench) [ğŸŒ](https://github.com/GerHobbelt/hashtable-bench) -- a benchmark for hash tables (hash maps) with different hash functions in C++, attempting to evaluate the performance of the lookup, insertion, deletion, iteration, etc. on different data as comprehensively as possible.
- **highwayhash** [ğŸ“](./highwayhash) [ğŸŒ](https://github.com/GerHobbelt/highwayhash) -- Fast strong hash functions: SipHash/HighwayHash
- **hopscotch-map** [ğŸ“](./hopscotch-map) [ğŸŒ](https://github.com/GerHobbelt/hopscotch-map) -- a C++ implementation of a fast hash map and hash set using hopscotch hashing and open-addressing to resolve collisions. It is a cache-friendly data structure offering better performances than `std::unordered_map` in most cases and is closely similar to `google::dense_hash_map` while using less memory and providing more functionalities.
- **iceberghashtable** [ğŸ“](./iceberghashtable) [ğŸŒ](https://github.com/GerHobbelt/iceberghashtable) -- [IcebergDB: High Performance Hash Tables Through Stability and Low Associativity](https://arxiv.org/abs/2210.04068) is a fast, concurrent, and resizeable hash table implementation. It supports insertions, deletions and queries for 64-bit keys and values.
- **LDCF-hash** [ğŸ“](./LDCF-hash) [ğŸŒ](https://github.com/GerHobbelt/LDCF) -- The Logarithmic Dynamic Cuckoo Filter (LDCF) is an efficient approximate membership test data structure for dynamic big data sets. LDCF uses a novel multi-level tree structure and reduces the worst insertion and membership testing time from O(N) to O(1), while simultaneously reducing the memory cost of DCF as the cardinality of the set increases.
- **libart** [ğŸ“](./libart) [ğŸŒ](https://github.com/GerHobbelt/libart) -- provides the Adaptive Radix Tree or ART. The ART operates similar to a traditional radix tree but avoids the wasted space of internal nodes by changing the node size. It makes use of 4 node sizes (4, 16, 48, 256), and can guarantee that the overhead is no more than 52 bytes per key, though in practice it is much lower.
- **libbloom** [ğŸ“](./libbloom) [ğŸŒ](https://github.com/GerHobbelt/bloomd) -- a high-performance C server, exposing bloom filters and operations over them. The rate of false positives can be tuned to meet application demands, but reducing the error rate rapidly increases the amount of memory required for the representation. Example: Bloom filters enable you to represent 1MM items with a false positive rate of 0.1% in 2.4MB of RAM.
- **libbloomfilters** [ğŸ“](./libbloomfilters) [ğŸŒ](https://github.com/GerHobbelt/libbloomfilters) -- **libbf** is a C++11 library which implements various Bloom filters, including:
  
  - A^2
  - Basic
  - Bitwise
  - Counting
  - Spectral MI
  - Spectral RM
  - Stable

- **libCRCpp** [ğŸ“](./libCRCpp) [ğŸŒ](https://github.com/GerHobbelt/CRCpp) -- easy to use and fast C++ CRC library.
- **libCSD** [ğŸ“](./libCSD) [ğŸŒ](https://github.com/GerHobbelt/libCSD) -- a C++ library providing some different techniques for managing string dictionaries in compressed space. These approaches are inspired on the paper: "Compressed String Dictionaries", Nieves R. Brisaboa, Rodrigo CÃ¡novas, Francisco Claude, Miguel A. MartÃ­nez-Prieto, and Gonzalo Navarro, 10th Symposium on Experimental Algorithms (SEA'2011), p.136-147, 2011.
- **libcuckoo** [ğŸ“](./libcuckoo) [ğŸŒ](https://github.com/GerHobbelt/libcuckoo) -- provides a high-performance, compact hash table that allows multiple concurrent reader and writer threads.
- **libhashish** [ğŸ“](./libhashish) [ğŸŒ](https://github.com/GerHobbelt/libhashish) -- non-cryptographic hash algorithms & various applications thereof (hash tables = dictionaries, bloom filters, ...)
- **lshbox** [ğŸ“](./lshbox) [ğŸŒ](https://github.com/GerHobbelt/LSHBOX) -- a C++ Toolbox of Locality-Sensitive Hashing for Large Scale Image Retrieval. Locality-Sensitive Hashing (LSH) is an efficient method for large scale image retrieval, and it achieves great performance in approximate nearest neighborhood searching.
  
  LSHBOX is a simple but robust C++ toolbox that provides several LSH algrithms, in addition, it can be integrated into Python and MATLAB languages. The following LSH algrithms have been implemented in LSHBOX, they are:
  
  * LSH Based on Random Bits Sampling
  * Random Hyperplane Hashing
  * LSH Based on Thresholding
  * LSH Based on p-Stable Distributions
  * [Spectral Hashing](http://www.cs.huji.ac.il/~yweiss/SpectralHashing/) (SH)
  * [Iterative Quantization](http://www.unc.edu/~yunchao/itq.htm) (ITQ)
  * Double-Bit Quantization Hashing (DBQ)
  * K-means Based Double-Bit Quantization Hashing (KDBQ)

- **map_benchmark** [ğŸ“](./map_benchmark) [ğŸŒ](https://github.com/GerHobbelt/map_benchmark) -- comprehensive benchmarks of C++ maps.
- **morton_filter** [ğŸ“](./morton_filter) [ğŸŒ](https://github.com/GerHobbelt/morton_filter) -- a [Morton filter](https://www.vldb.org/pvldb/vol11/p1041-breslow.pdf) -- a new approximate set membership data structure. A Morton filter is a modified cuckoo filter that is optimized for bandwidth-constrained systems. Morton filters use additional computation in order to reduce their off-chip memory traffic. Like a cuckoo filter, a Morton filter supports insertions, deletions, and lookup operations. It additionally adds high-throughput self-resizing, a feature of quotient filters, which allows a Morton filter to increase its capacity solely by leveraging its internal representation. This capability is in contrast to existing vanilla cuckoo filter implementations, which are static and thus require using a backing data structure that contains the full set of items to resize the filter. Morton filters can also be configured to use less memory than a cuckoo filter for the same error rate while simultaneously delivering insertion, deletion, and lookup throughputs that are, respectively, up to 15.5x, 1.3x, and 2.5x higher than a cuckoo filter. Morton filters in contrast to vanilla cuckoo filters do not require a power of two number of buckets but rather only a number that is a multiple of two. They also use fewer bits per item than a Bloom filter when the target false positive rate is less than around 1% to 3%.
- **mutable_rank_select** [ğŸ“](./mutable_rank_select) [ğŸŒ](https://github.com/GerHobbelt/mutable_rank_select) -- Rank/Select Queries over Mutable Bitmaps. Given a *mutable* bitmap `B[0..u)` where `n` bits are set, the *rank/select problem* asks for a data structure built from `B` that supports `rank(i)` (the number of bits set in `B[0..i]`, for 0 â‰¤ i < u), `select(i)` (the position of the i-th bit set, for 0 â‰¤ i < n), `flip(i)` (toggles `B[i]`, for 0 â‰¤ i < u) and `access(i)` (return `B[i]`, for 0 â‰¤ i < u). The input bitmap is partitioned into blocks and a tree index is built over them. The tree index implemented in the library is an optimized b-ary Segment-Tree with SIMD AVX2/AVX-512 instructions. You can test a block size of 256 or 512 bits, and various rank/select algorithms for the blocks such as broadword techniques, CPU intrinsics, and SIMD instructions.
- **nedtries** [ğŸ“](./nedtries) [ğŸŒ](https://github.com/GerHobbelt/nedtries) -- an in-place bitwise binary Fredkin trie algorithm which allows for near constant time insertions, deletions, finds, closest fit finds and iteration. On modern hardware it is approximately 50-100% faster than red-black binary trees, it handily beats even the venerable O(1) hash table for less than 3000 objects and it is barely slower than the hash table for 10000 objects. Past 10000 objects you probably ought to use a hash table though, and if you need nearest fit rather than close fit then red-black trees are still optimal.
- **OZBCBitmap** [ğŸ“](./OZBCBitmap) [ğŸŒ](https://github.com/GerHobbelt/OZBCBitmap) -- OZBC provides an efficent compressed bitmap to create bitmap indexes on high-cardinality columns. Bitmap indexes have traditionally been considered to work well for low-cardinality columns, which have a modest number of distinct values. The simplest and most common method of bitmap indexing on attribute A with K cardinality associates a bitmap with every attribute value V then the Vth bitmap rapresent the predicate A=V. This approach ensures an efficient solution for performing search but on high-cardinality attributes the size of the bitmap index increase dramatically. OZBC is a run-length-encoded hybrid compressed bitmap designed exclusively to create a bitmap indexes on L cardinality attributes where L>=16 and provide bitwise logical operations in running time complexity proportianl to the compressed bitmap size.
- **parallel-hashmap** [ğŸ“](./parallel-hashmap) [ğŸŒ](https://github.com/GerHobbelt/parallel-hashmap) -- a set of hash map implementations, as well as a btree alternative to std::map and std::set
- **phf-hash** [ğŸ“](./phf-hash) [ğŸŒ](https://github.com/GerHobbelt/phf) -- a simple implementation of the CHD perfect hash algorithm. CHD can generate perfect hash functions for very large key sets -- on the order of millions of keys -- in a very short time.
- **poplar-trie** [ğŸ“](./poplar-trie) [ğŸŒ](https://github.com/GerHobbelt/poplar-trie) -- a C++17 library of a memory-efficient associative array whose keys are strings. The data structure is based on a dynamic path-decomposed trie (DynPDT) described in the paper, Shunsuke Kanda, Dominik KÃ¶ppl, Yasuo Tabei, Kazuhiro Morita, and Masao Fuketa: [Dynamic Path-decomposed Tries](https://arxiv.org/abs/1906.06015), *ACM Journal of Experimental Algorithmics (JEA)*, *25*(1): 1â€“28, 2020. Poplar-trie is a memory-efficient updatable associative array implementation which maps key strings to values of any type like `std::map<std::string,anytype>`. DynPDT is composed of two structures: dynamic trie and node label map (NLM) structures.
- **PruningRadixTrie** [ğŸ“](./PruningRadixTrie) [ğŸŒ](https://github.com/GerHobbelt/PruningRadixTrie) -- a 1000x faster Radix trie for prefix search & auto-complete, the PruningRadixTrie is a novel data structure, derived from a radix trie - but 3 orders of magnitude faster. A **Pruning Radix trie** is a novel Radix trie algorithm, that allows pruning of the Radix trie and early termination of the lookup. In many cases, we are not interested in a complete set of all children for a given prefix, but only in the top-k most relevant terms. Especially for short prefixes, this results in a **massive reduction of lookup time** for the top-10 results. On the other hand, a complete result set of millions of suggestions wouldn't be helpful at all for autocompletion. The lookup acceleration is achieved by storing in each node the maximum rank of all its children. By comparing this maximum child rank with the lowest rank of the results retrieved so far, we can heavily prune the trie and do early termination of the lookup for non-promising branches with low child ranks.
- **prvhash** [ğŸ“](./prvhash) [ğŸŒ](https://github.com/GerHobbelt/prvhash) -- PRVHASH is a hash function that generates a [uniform pseudo-random number sequence](https://en.wikipedia.org/wiki/Pseudorandom_number_generator) derived from the message. PRVHASH is conceptually similar (in the sense of using a pseudo-random number sequence as a hash) to [`keccak`](https://en.wikipedia.org/wiki/SHA-3) and [`RadioGatun`](https://en.wikipedia.org/wiki/RadioGat%C3%BAn) schemes, but is a completely different implementation of such concept. PRVHASH is both a ["randomness extractor"](https://en.wikipedia.org/wiki/Randomness_extractor) and an "extendable-output function" (XOF).
- **QALSH** [ğŸ“](./QALSH) [ğŸŒ](https://github.com/GerHobbelt/QALSH) -- QALSH: Query-Aware Locality-Sensitive Hashing, is a package for the problem of Nearest Neighbor Search (NNS) over high-dimensional Euclidean spaces. Given a set of data points and a query, the problem of NNS aims to find the nearest data point to the query. It is a very fundamental probelm and has wide applications in many data mining and machine learning tasks. This package provides the external memory implementations (disk-based) of QALSH and QALSH<sup>+</sup> for *c*-Approximate Nearest Neighbor Search (c-ANNS) under *l<sub>p</sub>* norm, where *0 < p â©½ 2*. The internel memory version can be found [here](https://github.com/HuangQiang/QALSH_Mem).
- **QALSH_Mem** [ğŸ“](./QALSH_Mem) [ğŸŒ](https://github.com/GerHobbelt/QALSH_Mem) -- Memory Version of QALSH: **QALSH_Mem** is a package for the problem of Nearest Neighbor Search (NNS). Given a set of data points and a query, the problem of NNS aims to find the nearest data point to the query. It has wide applications in many data mining and machine learning tasks. This package provides the internal memory implementations of two LSH schemes QALSH and QALSH<sup>+</sup> for *c*-Approximate Nearest Neighbor Search (c-ANNS) under *l<sub>p</sub>* norm, where *0 < p â©½ 2*. The external version of QALSH and QALSH<sup>+</sup> can be found [here](https://github.com/HuangQiang/QALSH).
- **radix_tree** [ğŸ“](./radix_tree) [ğŸŒ](https://github.com/GerHobbelt/radix_tree) -- STL like container of radix tree in C++.
- **rankselect** [ğŸ“](./rankselect) [ğŸŒ](https://github.com/GerHobbelt/rankselect) -- space-efficient, high-performance rank & select structures on uncompressed bit sequences.
- **rapidhash** [ğŸ“](./rapidhash) [ğŸŒ](https://github.com/GerHobbelt/rapidhash) -- very fast, high quality, platform-independent, this is the fastest recommended hash function by [SMHasher](https://github.com/rurban/smhasher?tab=readme-ov-file#summary). The fastest passing hash in [SMHasher3](https://gitlab.com/fwojcik/smhasher3/-/blob/main/results/README.md#passing-hashes). rapidhash is [wyhash](https://github.com/wangyi-fudan/wyhash)' official successor, with improved speed, quality and compatibility.
- **rax** [ğŸ“](./rax) [ğŸŒ](https://github.com/GerHobbelt/rax) -- an ANSI C radix tree implementation initially written to be used in a specific place of Redis in order to solve a performance problem, but immediately converted into a stand alone project to make it reusable for Redis itself, outside the initial intended application, and for other projects as well. The primary goal was to find a suitable balance between performances and memory usage, while providing a fully featured implementation of radix trees that can cope with many different requirements.
- **RectangleBinPack** [ğŸ“](./RectangleBinPack) [ğŸŒ](https://github.com/GerHobbelt/RectangleBinPack) -- the source code used in "A Thousand Ways to Pack the Bin - A Practical Approach to Two-Dimensional Rectangle Bin Packing." The code can be
- **RoaringBitmap** [ğŸ“](./RoaringBitmap) [ğŸŒ](https://github.com/GerHobbelt/RoaringBitmap) -- Roaring bitmaps are compressed bitmaps which tend to outperform conventional compressed bitmaps such as WAH, EWAH or Concise. In some instances, roaring bitmaps can be hundreds of times faster and they often offer significantly better compression. They can even be faster than uncompressed bitmaps.
- **robin-hood-hashing** [ğŸ“](./robin-hood-hashing) [ğŸŒ](https://github.com/GerHobbelt/robin-hood-hashing) -- robin_hood unordered map & set.
- **robin-map** [ğŸ“](./robin-map) [ğŸŒ](https://github.com/GerHobbelt/robin-map) -- a C++ implementation of a fast hash map and hash set using open-addressing and linear robin hood hashing with backward shift deletion to resolve collisions.
- **rollinghashcpp** [ğŸ“](./rollinghashcpp) [ğŸŒ](https://github.com/GerHobbelt/rollinghashcpp) -- randomized rolling hash functions in C++. This is a set of C++ classes implementing various recursive n-gram hashing techniques, also called rolling hashing (http://en.wikipedia.org/wiki/Rolling_hash), including Randomized Karp-Rabin (sometimes called Rabin-Karp), Hashing by Cyclic Polynomials (also known as Buzhash) and Hashing by Irreducible Polynomials.
- **RTree** [ğŸ“](./RTree) [ğŸŒ](https://github.com/GerHobbelt/RTree) -- R-Tree: a Dynamic Index Structure for Spatial Searching, implemented as a C++ template, generally compatible with the STL and Boost C++ libraries.
- **semimap** [ğŸ“](./semimap) [ğŸŒ](https://github.com/GerHobbelt/semimap) -- semi::static_map and semi::map: associative map containers with compile-time lookup! Normally, associative containers require some runtime overhead when looking up their values from a key. However, when the key is known at compile-time (for example, when the key is a literal) then this run-time lookup could technically be avoided. This is exactly what the goal of `semi::static_map` and `semi::map` is.
- **SipHash** [ğŸ“](./SipHash) [ğŸŒ](https://github.com/GerHobbelt/SipHash) -- SipHash is a family of pseudorandom functions (PRFs) optimized for speed on short messages. This is the reference C code of SipHash: portable, simple, optimized for clarity and debugging. SipHash was designed in 2012 by [Jean-Philippe Aumasson](https://aumasson.jp) and [Daniel J. Bernstein](https://cr.yp.to) as a defense against [hash-flooding DoS attacks](https://aumasson.jp/siphash/siphashdos_29c3_slides.pdf).
  
  It is *simpler and faster* on short messages than previous cryptographic algorithms, such as MACs based on universal hashing, *competitive in performance* with insecure non-cryptographic algorithms, such as [fhhash](https://github.com/cbreeden/fxhash), *cryptographically secure*, with no sign of weakness despite multiple [cryptanalysis](https://eprint.iacr.org/2019/865) [projects](https://eprint.iacr.org/2019/865) by leading cryptographers, *battle-tested*, with successful integration in OSs (Linux kernel, OpenBSD, FreeBSD, FreeRTOS), languages (Perl, Python, Ruby, etc.), libraries (OpenSSL libcrypto, Sodium, etc.) and applications (Wireguard, Redis, etc.).
  
  As a secure pseudorandom function (a.k.a. keyed hash function), SipHash can also be used as a secure message authentication code (MAC). But SipHash is *not a hash* in the sense of general-purpose key-less hash function such as BLAKE3 or SHA-3. SipHash should therefore always be used with a secret key in order to be secure.

- **slot_map** [ğŸ“](./slot_map) [ğŸŒ](https://github.com/GerHobbelt/slot_map) -- a Slot Map is a high-performance associative container with persistent unique keys to access stored values. Upon insertion, a key is returned that can be used to later access or remove the values. Insertion, removal, and access are all guaranteed to take `O(1)` time (best, worst, and average case). Great for storing collections of objects that need stable, safe references but have no clear ownership. The difference between a `std::unordered_map` and a `dod::slot_map` is that the slot map generates and returns the key when inserting a value. A key is always unique and will only refer to the value that was inserted.
- **smhasher** [ğŸ“](./smhasher) [ğŸŒ](https://github.com/GerHobbelt/smhasher) -- benchmark and collection of fast hash functions for symbol tables or hash tables.
- **sparsehash** [ğŸ“](./sparsehash) [ğŸŒ](https://github.com/GerHobbelt/sparsehash) -- fast (non-cryptographic) hash algorithms
- **sparse-map** [ğŸ“](./sparse-map) [ğŸŒ](https://github.com/GerHobbelt/sparse-map) -- a C++ implementation of a memory efficient hash map and hash set. It uses open-addressing with sparse quadratic probing. The goal of the library is to be the most memory efficient possible, even at low load factor, while keeping reasonable performances.
- **sparsepp** [ğŸ“](./sparsepp) [ğŸŒ](https://github.com/GerHobbelt/sparsepp) -- a fast, memory efficient hash map for C++. Sparsepp is derived from Google's excellent [sparsehash](https://github.com/sparsehash/sparsehash) implementation.
- **spookyhash** [ğŸ“](./spookyhash) [ğŸŒ](https://github.com/GerHobbelt/spookyhash) -- a very fast non cryptographic hash function, [designed by Bob Jenkins](http://burtleburtle.net/bob/hash/spooky.html). It produces well-distributed 128-bit hash values for byte arrays of any length. It can produce 64-bit and 32-bit hash values too, at the same speed.
- **StronglyUniversalStringHashing** [ğŸ“](./StronglyUniversalStringHashing) [ğŸŒ](https://github.com/GerHobbelt/StronglyUniversalStringHashing) -- very fast [universal hash families](https://en.wikipedia.org/wiki/Universal_hashing) on strings.
- **tensorstore** [ğŸ“](./tensorstore) [ğŸŒ](https://github.com/GerHobbelt/tensorstore) -- TensorStore is an open-source C++ and Python software library designed for storage and manipulation of large multi-dimensional arrays.
- **thumbhash** [ğŸ“](./thumbhash) [ğŸŒ](https://github.com/GerHobbelt/thumbhash) -- ThumbHash: a very compact representation of a placeholder for an image. Store it inline with your data and show it while the real image is loading for a smoother loading experience. It's similar to [BlurHash](https://github.com/woltapp/blurhash) but encodes more detail in the same space, also encodes the aspect ratio and gives more accurate colors.
- **unordered_dense** [ğŸ“](./unordered_dense) [ğŸŒ](https://github.com/GerHobbelt/unordered_dense) -- `ankerl::unordered_dense::{map, set}` is a fast & densely stored hashmap and hashset based on robin-hood backward shift deletion for C++17 and later. The classes `ankerl::unordered_dense::map` and `ankerl::unordered_dense::set` are (almost) drop-in replacements of `std::unordered_map` and `std::unordered_set`. While they don't have as strong iterator / reference stability guaranties, they are typically *much* faster. Additionally, there are `ankerl::unordered_dense::segmented_map` and `ankerl::unordered_dense::segmented_set` with lower peak memory usage. and stable iterator/references on insert.
- **vqf** [ğŸ“](./vqf) [ğŸŒ](https://github.com/GerHobbelt/vqf) -- Vector Quotient Filters: Overcoming the Time/Space Trade-Off in Filter Design. The VQF supports approximate membership testing of items in a data set. The VQF is based on Robin Hood hashing, like the quotient filter, but uses power-of-two-choices hashing to reduce the variance of runs, and thus offers consistent, high throughput across load factors. Power-of-two-choices hashing also makes it more amenable to concurrent updates.
- **wyhash** [ğŸ“](./wyhash) [ğŸŒ](https://github.com/GerHobbelt/wyhash) -- No hash function is perfect, but some are useful. `wyhash` and `wyrand` are the ideal 64-bit hash function and PRNG respectively: solid, portable, fastest (especially for short keys), salted (using a dynamic secret to avoid intended attack).
- **xor-and-binary-fuse-filter** [ğŸ“](./xor-and-binary-fuse-filter) [ğŸŒ](https://github.com/GerHobbelt/xor_singleheader) -- XOR and Binary Fuse Filter library: Bloom filters are used to quickly check whether an element is part of a set. Xor filters and binary fuse filters are faster and more concise alternative to Bloom filters. They are also smaller than cuckoo filters. They are used in [production systems](https://github.com/datafuselabs/databend).
- **xsg** [ğŸ“](./xsg) [ğŸŒ](https://github.com/GerHobbelt/xsg) -- XOR [BST](https://en.wikipedia.org/wiki/Binary_search_tree) implementations are related to the [XOR linked list](https://en.wikipedia.org/wiki/XOR_linked_list), a [doubly linked list](https://en.wikipedia.org/wiki/Doubly_linked_list) variant, from where we borrow the idea about how links between nodes are to be implemented. Modest resource requirements and simplicity make XOR [scapegoat trees](https://en.wikipedia.org/wiki/Scapegoat_tree) stand out of the [BST](https://en.wikipedia.org/wiki/Binary_search_tree) crowd. All iterators (except `end()` iterators), but not references and pointers, are invalidated, after inserting or erasing from this XOR [scapegoat tree](https://en.wikipedia.org/wiki/Scapegoat_tree) implementation. You can dereference invalidated iterators, if they were not erased, but you cannot iterate with them. `end()` iterators are constant and always valid, but dereferencing them results in undefined behavior.
- **xxHash** [ğŸ“](./xxHash) [ğŸŒ](https://github.com/GerHobbelt/xxHash) -- fast (non-cryptographic) hash algorithm
- ~~**circlehash** [ğŸ“](./circlehash) [ğŸŒ](https://github.com/GerHobbelt/circlehash) -- a family of non-cryptographic hash functions that pass every test in SMHasher.~~
  
  - **removed**; reason: written in Go; port to C/C++ is easy but just too much effort for too little gain; when we're looking for *fast* non-cryptographic hashes like this, we don't appreciate it to include 128-bit / 64-bit multiplications as those are generally slower than shift, add, xor. While this will surely be a nice hash, it doesn't fit our purposes.
















	
----

ğŸ¡¸ [previous section](./0014-content.md)  |  ğŸ¡¹ [up](./0006-libraries-we-re-looking-at-for-this-intent.md)  |  ğŸ¡» [all (index)](./0093-libraries-in-this.md)  |  ğŸ¡º [next section](./0016-intermediate-data-storage-caching-hierarchical-data.md)
